# app.py
import os
import io
import json
import base64
import time
import asyncio
import traceback
from pathlib import Path
from typing import Optional, Tuple

from fastapi import FastAPI, Request
import httpx
from PIL import Image, ImageOps, ImageFilter

# ================= CONFIG =================
BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN", "")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")  # –∏–ª–∏ "gpt-4o"

# –ü—Ä–æ—Ñ–∏–ª–∏ —Å–∂–∞—Ç–∏—è (–¥–µ—à—ë–≤—ã–π –∏ ¬´—Å–ø–∞—Å–∞—Ç–µ–ª—å–Ω—ã–π¬ª –¥–æ—Ä–æ–≥–æ–π)
LOW_MAX_SIDE = 640
LOW_JPEG_Q   = 60
LOW_DETAIL   = "low"

HIGH_MAX_SIDE = 768
HIGH_JPEG_Q   = 72
HIGH_DETAIL   = "high"

API_URL  = f"https://api.telegram.org/bot{BOT_TOKEN}"
FILE_URL = f"https://api.telegram.org/file/bot{BOT_TOKEN}"

APP_VERSION = "build-2025-10-16-03"
print(f"[BOOT] {APP_VERSION} | model={OPENAI_MODEL} | LOW={LOW_MAX_SIDE}/{LOW_JPEG_Q}/{LOW_DETAIL} | HIGH={HIGH_MAX_SIDE}/{HIGH_JPEG_Q}/{HIGH_DETAIL}")

# ================ APP ======================
app = FastAPI()
DOWNLOAD_DIR = Path("/tmp/tg_photos")
DOWNLOAD_DIR.mkdir(parents=True, exist_ok=True)

SEEN: dict[int, float] = {}  # anti-dup

# ------------- Telegram helpers -------------
async def tg_api(method: str, payload: dict):
    async with httpx.AsyncClient(timeout=25) as client:
        r = await client.post(f"{API_URL}/{method}", json=payload)
        if r.status_code != 200:
            print("TG API ERROR", r.status_code, r.text)
        r.raise_for_status()
        return r.json()

async def tg_send_message(chat_id: int | str, text: str, reply_to: Optional[int] = None):
    payload = {"chat_id": chat_id, "text": text}
    if reply_to:
        payload["reply_to_message_id"] = reply_to
    try:
        return await tg_api("sendMessage", payload)
    except Exception as e:
        print("sendMessage failed:", e)
        print(traceback.format_exc())

async def tg_get_file(file_id: str) -> str:
    data = await tg_api("getFile", {"file_id": file_id})
    return data["result"]["file_path"]

async def tg_download_file(file_path: str) -> Path:
    url = f"{FILE_URL}/{file_path}"
    local = DOWNLOAD_DIR / Path(file_path).name
    async with httpx.AsyncClient(timeout=60) as client:
        r = await client.get(url)
        if r.status_code != 200:
            print("FILE GET ERROR", r.status_code, r.text)
        r.raise_for_status()
        local.write_bytes(r.content)
    return local

# ---------------- Image helpers -------------------
def _trim_whitespace(img_l: Image.Image, thresh: int = 245) -> Image.Image:
    bw = img_l.point(lambda p: 255 if p > thresh else 0, mode="L")
    bbox = bw.getbbox()
    if bbox:
        return img_l.crop(bbox)
    return img_l

def encode_image_b64(path: Path, max_side: int, quality: int, apply_median: bool) -> Tuple[str, str]:
    """
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (base64, –ª–æ–≥_—Å—Ç—Ä–æ–∫–∞). –î–ª—è –≤—ã—Å–æ–∫–æ–≥–æ –ø—Ä–æ—Ñ–∏–ª—è –º–µ–¥–∏–∞–Ω-—Ñ–∏–ª—å—Ç—Ä –æ—Ç–∫–ª—é—á–∞–µ–º,
    —á—Ç–æ–±—ã –Ω–µ —Å–º–∞–∑—ã–≤–∞—Ç—å —Ç–æ–Ω–∫–∏–µ —à—Ç—Ä–∏—Ö–∏.
    """
    img = Image.open(path).convert("L")
    w0, h0 = img.size

    img = _trim_whitespace(img, thresh=245)

    w1, h1 = img.size
    if apply_median:
        img = img.filter(ImageFilter.MedianFilter(size=3))  # —Ç–æ–ª—å–∫–æ –≤ –¥–µ—à—ë–≤–æ–º –ø—Ä–æ–≥–æ–Ω–µ

    scale = max(w1, h1) / max_side if max(w1, h1) > max_side else 1.0
    if scale > 1.0:
        img = img.resize((int(w1/scale), int(h1/scale)), Image.LANCZOS)

    img = ImageOps.autocontrast(img, cutoff=1)

    buf = io.BytesIO()
    img.save(buf, format="JPEG", quality=quality, optimize=True, progressive=True)
    jpeg_bytes = buf.getvalue()
    b64 = base64.b64encode(jpeg_bytes).decode("ascii")

    log = (f"original {w0}x{h0} -> trimmed {w1}x{h1} -> resized {img.size[0]}x{img.size[1]}, "
           f"jpeg={len(jpeg_bytes)/1024:.1f}KB, b64_len={len(b64)}, MAX_SIDE={max_side}, Q={quality}, "
           f"median={'on' if apply_median else 'off'}")
    return b64, log

# ---------------- OpenAI call ---------------------
async def call_openai(img_b64: str, detail: str) -> dict:
    system_prompt = """–¢—ã ‚Äî —Å—Ç—Ä–æ–≥–∏–π –∏ –¥–æ–±—Ä–æ–∂–µ–ª–∞—Ç–µ–ª—å–Ω—ã–π —É—á–∏—Ç–µ–ª—å –º–∞—Ç–µ–º–∞—Ç–∏–∫–∏ 7‚Äì9 –∫–ª–∞—Å—Å–æ–≤.
1) –°—á–∏—Ç–∞–π —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç —É—á–µ–Ω–∏–∫–∞ (–µ—Å–ª–∏ –≤–∏–¥–µ–Ω).
2) –†–µ—à–∏ –∑–∞–¥–∞—á—É —Å–∞–º –∏ –ø–æ–ª—É—á–∏ —Å–≤–æ–π —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç.
3) –°—Ä–∞–≤–Ω–∏: —Ü–µ–ª—ã–µ ‚Äî —Å—Ç—Ä–æ–≥–æ; –¥–µ—Å—è—Ç–∏—á–Ω—ã–µ ‚Äî —Å –ø–æ–≥—Ä–µ—à–Ω–æ—Å—Ç—å—é 1e-3 –∏–ª–∏ 1%.
4) –£–∫–∞–∑—ã–≤–∞–π –¢–û–õ–¨–ö–û —Ä–µ–∞–ª—å–Ω—ã–µ –æ—à–∏–±–∫–∏ —Ö–æ–¥–∞ (–Ω–µ—Ä–∞–∑–±–æ—Ä—á–∏–≤–æ ‚â† –æ—à–∏–±–∫–∞).
5) –ï—Å–ª–∏ –∏—Ç–æ–≥ –≤–µ—Ä–Ω—ã–π –∏ –æ—à–∏–±–æ–∫ —Ö–æ–¥–∞ –Ω–µ—Ç ‚Äî –Ω–µ –ø—Ä–µ–¥–ª–∞–≥–∞–π —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫—É.
6) –ï—Å–ª–∏ –≤–∏–¥–∏–º–æ—Å—Ç—å –ø–ª–æ—Ö–∞—è ‚Äî —á–µ—Å—Ç–Ω–æ —É–∫–∞–∂–∏ —ç—Ç–æ –∏ –Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –æ—à–∏–±–∫–∏.
–û—Ç–≤–µ—Ç —Å—Ç—Ä–æ–≥–æ –≤ JSON.
"""

    user_prompt = """–í–µ—Ä–Ω–∏ –†–û–í–ù–û —Ç–∞–∫–æ–π JSON:
{
  "confidence": 0.0,
  "student_final_answer": null,
  "model_final_answer": null,
  "is_final_answer_correct": null,
  "steps_student": [],
  "step_issues": [],
  "gaps": [],
  "need_drills": false,
  "drills": [],
  "summary": "‚Ä¶"
}
–ü—Ä–∞–≤–∏–ª–∞ –≤—ã–≤–æ–¥–∞:
- –ï—Å–ª–∏ –∏—Ç–æ–≥ –≤–µ—Ä–Ω—ã–π –∏ –Ω–µ—Ç –æ—à–∏–±–æ–∫ —Ö–æ–¥–∞ ‚Äî need_drills=false –∏ drills –ø—É—Å—Ç.
- –ï—Å–ª–∏ –∑–∞–ø–∏—Å—å –Ω–µ—Ä–∞–∑–±–æ—Ä—á–∏–≤–∞ ‚Äî —É–∫–∞–∂–∏ —ç—Ç–æ –≤ summary –∏ –Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –æ—à–∏–±–∫–∏.
"""

    headers = {
        "Authorization": f"Bearer {OPENAI_API_KEY}",
        "Content-Type": "application/json",
    }
    payload = {
        "model": OPENAI_MODEL,
        "messages": [
            {"role": "system", "content": system_prompt},
            {
                "role": "user",
                "content": [
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{img_b64}",
                            "detail": detail
                        },
                    },
                    {"type": "text", "text": user_prompt},
                ],
            },
        ],
        "temperature": 0.0,
        "max_tokens": 300,
    }

    start = time.time()
    print(f"[AI] model={OPENAI_MODEL}, detail={detail}, max_tokens=300, temp=0.0, image_b64_len={len(img_b64)}")

    async with httpx.AsyncClient(timeout=90) as client:
        r = await client.post("https://api.openai.com/v1/chat/completions",
                              headers=headers, json=payload)
        if r.status_code != 200:
            print("OpenAI ERROR", r.status_code, r.text)
        r.raise_for_status()
        data = r.json()

    try:
        u = data.get("usage", {})
        print(f"[AI] usage: prompt={u.get('prompt_tokens')} completion={u.get('completion_tokens')} total={u.get('total_tokens')} time={(time.time()-start):.2f}s")
    except Exception:
        pass

    # –ü–∞—Ä—Å –æ—Ç–≤–µ—Ç–∞ –≤ JSON
    raw = data["choices"][0]["message"]["content"]
    try:
        return json.loads(raw)
    except Exception:
        try:
            return json.loads((raw or "").strip().strip("`").strip())
        except Exception:
            print("JSON parse failed. Raw:", (raw or "")[:500])
            return {
                "confidence": 0.0,
                "student_final_answer": None,
                "model_final_answer": None,
                "is_final_answer_correct": None,
                "steps_student": [],
                "step_issues": [],
                "gaps": [],
                "need_drills": False,
                "drills": [],
                "summary": "–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–¥—ë–∂–Ω–æ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å –∑–∞–ø–∏—Å—å. –ü–µ—Ä–µ—Å–Ω–∏–º–∏—Ç–µ –∫—Ä—É–ø–Ω–µ–µ/—Ä–µ–∑—á–µ."
            }

def is_unreadable(result: dict) -> bool:
    """–ö—Ä–∏—Ç–µ—Ä–∏–∏, –∫–æ–≥–¥–∞ —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ –º–æ–¥–µ–ª—å –Ω–µ —Å–º–æ–≥–ª–∞ –ø—Ä–æ—á–∏—Ç–∞—Ç—å."""
    conf = result.get("confidence")
    summary = (result.get("summary") or "").lower()
    no_content = not result.get("steps_student") and result.get("student_final_answer") in (None, "", "null")
    conf_bad = (isinstance(conf, (int, float)) and conf < 0.4)
    mentions_blurry = any(word in summary for word in ["–Ω–µ—Ä–∞–∑–±–æ—Ä—á", "–ø–ª–æ—Ö–æ –≤–∏–¥–Ω–æ", "—Ä–∞–∑–º—ã—Ç–æ", "–Ω–µ –≤–∏–∂—É"])
    return no_content or conf_bad or mentions_blurry

async def analyze_math_image(image_path: Path) -> dict:
    """
    –î–≤—É—Ö—Å—Ç—É–ø–µ–Ω—á–∞—Ç—ã–π –∞–Ω–∞–ª–∏–∑:
      Pass A (–¥–µ—à—ë–≤—ã–π): 640/60, detail=low, —Å –º–µ–¥–∏–∞–Ω-—Ñ–∏–ª—å—Ç—Ä–æ–º.
      –ï—Å–ª–∏ –Ω–µ—á–∏—Ç–∞–±–µ–ª—å–Ω–æ -> Pass B (–¥–æ—Ä–æ–≥–æ–π): 768/72, detail=high, –±–µ–∑ –º–µ–¥–∏–∞–Ω-—Ñ–∏–ª—å—Ç—Ä–∞.
    """
    # Pass A
    b64_low, log_low = encode_image_b64(image_path, LOW_MAX_SIDE, LOW_JPEG_Q, apply_median=True)
    print(f"[IMG/LOW] {log_low}")
    res_low = await call_openai(b64_low, LOW_DETAIL)

    if not is_unreadable(res_low):
        res_low["_profile"] = "low"
        return res_low

    print("[FALLBACK] low-profile unreadable ‚Üí retry with HIGH profile")
    # Pass B
    b64_high, log_high = encode_image_b64(image_path, HIGH_MAX_SIDE, HIGH_JPEG_Q, apply_median=False)
    print(f"[IMG/HIGH] {log_high}")
    res_high = await call_openai(b64_high, HIGH_DETAIL)
    res_high["_profile"] = "high"
    return res_high

# ---------------- Formatting ---------------------
def format_report(j: dict) -> str:
    conf  = j.get("confidence")
    s_ans = j.get("student_final_answer")
    m_ans = j.get("model_final_answer")
    ok    = j.get("is_final_answer_correct")
    steps = j.get("steps_student") or []
    issues = j.get("step_issues") or []
    gaps   = j.get("gaps") or []
    need   = bool(j.get("need_drills"))
    drills = j.get("drills") or []
    summary = j.get("summary") or ""
    profile = j.get("_profile", "low")

    out = [f"–ü—Ä–æ—Ñ–∏–ª—å –∞–Ω–∞–ª–∏–∑–∞: {('—ç–∫–æ–Ω–æ–º–∏—á–Ω—ã–π' if profile=='low' else '–ø–æ–≤—ã—à–µ–Ω–Ω–æ–π —Ç–æ—á–Ω–æ—Å—Ç–∏')}."]
    if ok is True:
        out.append("‚úÖ –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç–≤–µ—Ç: –í–ï–†–ù–û.")
    elif ok is False:
        out.append("‚ùå –ò—Ç–æ–≥–æ–≤—ã–π –æ—Ç–≤–µ—Ç: –ù–ï–í–ï–†–ù–û.")
    else:
        out.append("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–¥—ë–∂–Ω–æ –ø—Ä–æ—á–∏—Ç–∞—Ç—å —Ñ–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç —É—á–µ–Ω–∏–∫–∞.")

    if s_ans is not None:
        out.append(f"–û—Ç–≤–µ—Ç —É—á–µ–Ω–∏–∫–∞: {s_ans}")
    if m_ans is not None:
        out.append(f"–ü—Ä–æ–≤–µ—Ä–æ—á–Ω—ã–π –æ—Ç–≤–µ—Ç: {m_ans}")
    if isinstance(conf, (int, float)):
        try:
            out.append(f"–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: {round(float(conf)*100)}%")
        except Exception:
            pass
    out.append("")

    if steps:
        out.append("–®–∞–≥–∏ —É—á–µ–Ω–∏–∫–∞ (–∫–∞–∫ —á–∏—Ç–∞—é—Ç—Å—è —Å —Ñ–æ—Ç–æ):")
        for i, s in enumerate(steps, 1):
            out.append(f"{i}) {s}")
        out.append("")

    if issues:
        out.append("–û—à–∏–±–∫–∏/–Ω–µ–¥–æ—á—ë—Ç—ã —Ö–æ–¥–∞ —Ä–µ—à–µ–Ω–∏—è:")
        for m in issues:
            step = m.get("step", "‚Äî")
            mtype = m.get("type", "‚Äî")
            why = m.get("why", "")
            out.append(f"‚Ä¢ {step}: {mtype}. {why}")
        out.append("")

    if issues and gaps:
        out.append("–í–µ—Ä–æ—è—Ç–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã:")
        for g in gaps:
            out.append(f"‚Ä¢ {g}")
        out.append("")

    if need and drills:
        out.append("–ú–∏–Ω–∏-—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞:")
        for d in drills:
            out.append(f"‚Ä¢ {d}")
        out.append("")

    if summary:
        out.append(f"–ò—Ç–æ–≥: {summary}")

    msg = "\n".join(out).strip()
    return msg[:4000] if len(msg) > 4000 else msg

# --------------- Background task ---------------
async def process_photo(chat_id: int, reply_to: Optional[int], file_id: str):
    try:
        file_path = await tg_get_file(file_id)
        local_path = await tg_download_file(file_path)

        report = await analyze_math_image(local_path)
        text_report = format_report(report) or \
            "–ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –æ—Ç—á—ë—Ç. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Å–Ω—è—Ç—å —Ñ–æ—Ç–æ –∫—Ä—É–ø–Ω–µ–µ/—Ä–µ–∑—á–µ."

        await tg_send_message(chat_id, text_report)
    except httpx.HTTPError as e:
        print("HTTP error during analysis:", e)
        await tg_send_message(chat_id, "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≤—è–∑–∞—Ç—å—Å—è —Å —Å–µ—Ä–≤–∏—Å–æ–º –∞–Ω–∞–ª–∏–∑–∞. –ü–æ–ø—Ä–æ–±—É–π –ø–æ–∑–∂–µ.")
    except Exception as e:
        print("Analysis error:", e)
        print(traceback.format_exc())
        await tg_send_message(
            chat_id,
            "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ñ–æ—Ç–æ üòï\n"
            "–°–¥–µ–ª–∞–π —Å–Ω–∏–º–æ–∫ –±–ª–∏–∂–µ –∏ —á—ë—Ç—á–µ, –ø–æ –æ–¥–Ω–æ–º—É –∑–∞–¥–∞–Ω–∏—é –Ω–∞ —Ñ–æ—Ç–æ."
        )

# --------------------- Routes ---------------------
@app.get("/")
def health():
    return {"status": "ok"}

@app.get("/debug")
def debug():
    return {
        "version": APP_VERSION,
        "model": OPENAI_MODEL,
        "LOW": {"MAX_SIDE": LOW_MAX_SIDE, "Q": LOW_JPEG_Q, "detail": LOW_DETAIL},
        "HIGH": {"MAX_SIDE": HIGH_MAX_SIDE, "Q": HIGH_JPEG_Q, "detail": HIGH_DETAIL},
    }

@app.post("/webhook/telegram")
async def tg_webhook(request: Request):
    global SEEN
    try:
        update = await request.json()
        message = update.get("message") or update.get("edited_message")
        if not message:
            return {"ok": True}

        chat_id = message["chat"]["id"]
        message_id = message.get("message_id")
        text = message.get("text") or ""
        photos = message.get("photo") or []

        now = time.time()
        if message_id in SEEN and now - SEEN[message_id] < 60:
            print(f"[DEDUP] skip message_id {message_id}")
            return {"ok": True}
        SEEN[message_id] = now

        if text.startswith("/start"):
            asyncio.create_task(
                tg_send_message(
                    chat_id,
                    "–ü—Ä–∏–≤–µ—Ç! –û—Ç–ø—Ä–∞–≤—å —Ñ–æ—Ç–æ –∑–∞–¥–∞—á–∏ (–ª—É—á—à–µ –ø–æ –æ–¥–Ω–æ–π –Ω–∞ —Ñ–æ—Ç–æ). "
                    "–Ø –ø—Ä–æ–≤–µ—Ä—é –∏—Ç–æ–≥, –æ—Ç–º–µ—á—É —Ä–µ–∞–ª—å–Ω—ã–µ –Ω–µ–¥–æ—á—ë—Ç—ã –∏ –¥–∞–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏.\n\n"
                    "–õ–∞–π—Ñ—Ö–∞–∫: —Å–Ω–∏–º–∞–π –∫—Ä—É–ø–Ω–æ –∏ –ø—Ä–∏ —Ö–æ—Ä–æ—à–µ–º —Å–≤–µ—Ç–µ.",
                    reply_to=message_id,
                )
            )
            return {"ok": True}

        if photos:
            largest = photos[-1]
            file_id = largest["file_id"]
            asyncio.create_task(tg_send_message(chat_id, "–§–æ—Ç–æ –ø–æ–ª—É—á–µ–Ω–æ ‚úÖ –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é‚Ä¶", reply_to=message_id))
            asyncio.create_task(process_photo(chat_id, message_id, file_id))
            return {"ok": True}

        if text:
            asyncio.create_task(tg_send_message(chat_id, f"–Ø –ø–æ–ª—É—á–∏–ª: {text}", reply_to=message_id))
            return {"ok": True}

        asyncio.create_task(tg_send_message(chat_id, "–ü—Ä–∏—à–ª–∏ /start –∏–ª–∏ –æ—Ç–ø—Ä–∞–≤—å —Ñ–æ—Ç–æ."))
        return {"ok": True}

    except Exception as e:
        print("Webhook handler error:", e)
        print(traceback.format_exc())
        return {"ok": True}
